{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a2fbac9-6621-4831-9ad4-2d7dcf7a23fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db121916-121c-46e3-b40e-87ad332707a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 入力データの受け取り"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdc7f9e6-d625-44de-a778-7660c022e6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "テキストの文字数 : 3660\n",
      "最初の30文字 :  GMOグローバルサイン・ホールディングスCTO室のZulfa\n"
     ]
    }
   ],
   "source": [
    "with open('./train.txt','r',encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "\n",
    "print(\"テキストの文字数 :\", len(text))\n",
    "print(\"最初の30文字 : \",text[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e0fbdc6-4e4f-42ab-9f73-f9d7b26aa88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習データで使っている文字数　：　 381\n",
      "トークン化した学習データ　：　 tensor([ 24,  28,  30, 134, 162, 165, 148, 161, 135, 130, 163, 164, 153, 165,\n",
      "        161, 146, 129, 163, 134, 138,  21,  35,  30, 230, 107,  40,  61,  53,\n",
      "         48,  43])\n"
     ]
    }
   ],
   "source": [
    "## 重複なしソート入力文字\n",
    "chars = sorted(list(set(text)))\n",
    "## 種類数\n",
    "char_size = len(chars)\n",
    "## 文字→数値、数値→文字の辞書\n",
    "char2int = { ch : i for i, ch in enumerate(chars) }\n",
    "int2char = { i : ch for i, ch in enumerate(chars) }\n",
    "## エンコード、デコードできる関数\n",
    "encode = lambda a: [char2int[b] for b in a ]\n",
    "decode = lambda a: ''.join([int2char[b] for b in a ])\n",
    "train_data = torch.tensor(encode(text), dtype=torch.long)\n",
    "\n",
    "print(\"学習データで使っている文字数　：　\", char_size)\n",
    "print(\"トークン化した学習データ　：　\", train_data[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f06e32cd-953e-4425-ac15-f85382282789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "埋め込みベクトルの次元数 :  3\n",
      "ベクトル表現 :  tensor([[ 1.3751, -0.1629, -1.1079],\n",
      "        [-0.2423, -1.2842,  0.6985],\n",
      "        [ 0.0325,  2.1288, -0.2214],\n",
      "        [-0.3532, -0.9633,  0.5138],\n",
      "        [ 0.8173,  0.3703,  0.0062]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "## 1文字を何次元のベクトル表現にするか\n",
    "vector_size = 3\n",
    "embeddings = nn.Embedding(char_size, vector_size)\n",
    "encoded_words = torch.tensor(encode(\"前回の記事\"))\n",
    "embeddings_words  = embeddings(encoded_words)\n",
    "print(\"埋め込みベクトルの次元数 : \",vector_size)\n",
    "print(\"ベクトル表現 : \",embeddings_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21095d62-b6f5-41e5-8cb1-2f0c6f854363",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
